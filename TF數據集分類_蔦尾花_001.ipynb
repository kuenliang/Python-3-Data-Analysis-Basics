{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF數據集分類_蔦尾花_001.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kuenliang/Python-3-Data-Analysis-Basics/blob/master/TF%E6%95%B8%E6%93%9A%E9%9B%86%E5%88%86%E9%A1%9E_%E8%94%A6%E5%B0%BE%E8%8A%B1_001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBbrlh5mW6Fp",
        "colab_type": "text"
      },
      "source": [
        "#Custom training: walkthrough\n",
        "##TensorFlow編程\n",
        "本指南使用這些高級TensorFlow概念：\n",
        "* 啟用熱切的執行開發環境，\n",
        "* 使用Datasets API導入數據，\n",
        "* 使用TensorFlow的Keras API構建模型和圖層。\n",
        "\n",
        "##TensorFlow programming\n",
        "This guide uses these high-level TensorFlow concepts:\n",
        "* Enable an eager execution development environment,\n",
        "* Import data with the Datasets API,\n",
        "* Build models and layers with TensorFlow's Keras API.\n",
        "This tutorial is structured like many TensorFlow programs:\n",
        "\n",
        "1. Import and parse the data sets.\n",
        "2. Select the type of model.\n",
        "3. Train the model.\n",
        "4. Evaluate the model's effectiveness.\n",
        "5. Use the trained model to make predictions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boqyVZTB2OnS",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mme1emHsYHcd",
        "colab_type": "text"
      },
      "source": [
        "##Setup program ：\n",
        "1. Configure imports and eager execution\n",
        "2. Import the required Python modules—including TensorFlow—and enable eager execution for this program. \n",
        "3. Eager execution makes TensorFlow evaluate operations immediately, returning concrete values instead of creating a computational graph that is executed later. 4. If you are used to a REPL or the python interactive console, this feels familiar. Eager execution is available in Tensorlow >=1.8.\n",
        "\n",
        "Once eager execution is enabled, it cannot be disabled within the same program. See the eager execution guide for more details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVDv22FZWsNk",
        "colab_type": "code",
        "outputId": "ce2642e0-d808-48f5-b7ee-7f987b1227f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import os \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "print(\"TensorFlow version:{}\".format(tf.__version__))\n",
        "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version:1.14.0\n",
            "Eager execution: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2ot3iaObOMP",
        "colab_type": "text"
      },
      "source": [
        "##The Iris classification problem\n",
        "* Imagine you are a botanist seeking an automated way to categorize each Iris flower you find. \n",
        "* Machine learning provides many algorithms to classify flowers statistically. For instance, a sophisticated machine learning program could classify flowers based on photographs. \n",
        "* Our ambitions are more modest—we're going to classify Iris flowers based on the length and width measurements of their sepals and petals.\n",
        "\n",
        "The Iris genus entails about 300 species, but our program will only classify the following three:\n",
        "\n",
        "1. Iris setosa\n",
        "2. Iris virginica\n",
        "3. Iris versicolor\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://www.tensorflow.org/images/iris_three_species.jpg\"\n",
        "         alt=\"Petal geometry compared for three iris species: Iris setosa, Iris virginica, and Iris versicolor\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figure 1.</b> <a href=\"https://commons.wikimedia.org/w/index.php?curid=170298\">Iris setosa</a> (by <a href=\"https://commons.wikimedia.org/wiki/User:Radomil\">Radomil</a>, CC BY-SA 3.0), <a href=\"https://commons.wikimedia.org/w/index.php?curid=248095\">Iris versicolor</a>, (by <a href=\"https://commons.wikimedia.org/wiki/User:Dlanglois\">Dlanglois</a>, CC BY-SA 3.0), and <a href=\"https://www.flickr.com/photos/33397993@N05/3352169862\">Iris virginica</a> (by <a href=\"https://www.flickr.com/photos/33397993@N05\">Frank Mayfield</a>, CC BY-SA 2.0).<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTqa1AAccls8",
        "colab_type": "text"
      },
      "source": [
        "##Import and parse the training dataset\n",
        "Download the dataset file and convert it into a structure that can be used by this Python program.\n",
        "\n",
        "###Download the dataset\n",
        "Download the training dataset file using the [tf.keras.utils.get_file](https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file) function. This returns the file path of the downloaded file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ssF_cGcb3wv",
        "colab_type": "code",
        "outputId": "27015411-924c-4771-b3d6-f2a94976571a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "train_dataset_url=\"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\"\n",
        "\n",
        "train_dataset_fp = tf.keras.utils.get_file(fname=os.path.basename(train_dataset_url),\n",
        "                                          origin=train_dataset_url)\n",
        "\n",
        "print(\"Local copy of the dataset file:{}\".format(train_dataset_fp))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\n",
            "8192/2194 [================================================================================================================] - 0s 0us/step\n",
            "Local copy of the dataset file:/root/.keras/datasets/iris_training.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3tUp6OcgT5c",
        "colab_type": "text"
      },
      "source": [
        "##Inspect the data ：\n",
        "* This dataset, `iris_training.csv`, is a plain text file that stores tabular data formatted as comma-separated values (CSV). \n",
        "* Use the `head -n5 `command to take a peak at the first five entries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A0yy4kLhKHK",
        "colab_type": "code",
        "outputId": "7cf797d2-d66e-4c83-8554-d8cbe5f9fca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "!head -n5 {train_dataset_fp}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120,4,setosa,versicolor,virginica\n",
            "6.4,2.8,5.6,2.2,2\n",
            "5.0,2.3,3.3,1.0,1\n",
            "4.9,2.5,4.5,1.7,2\n",
            "4.9,3.1,1.5,0.1,0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0E2PBgTlha0x",
        "colab_type": "text"
      },
      "source": [
        "###從數據集的此視圖中，請注意以下內容：\n",
        "1. 第一行是包含有關數據集的信息的標題：\n",
        "* 總共有120個例子。每個示例都有`四個功能`和`三個可能的標籤名稱`之一。\n",
        "* 後續行是數據記錄，每行一個示例，其中：`前四個字段是特徵`：這些是示例的特徵。這裡，字段包含代表花卉測量值的浮點數。\n",
        "* 最後一列是標籤：這是我們想要預測的值。對於此數據集，它是與花名稱對應的整數值0,1或2。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWotHRFbikaW",
        "colab_type": "code",
        "outputId": "61a6f2b9-9fe5-4f99-fe5d-6068593dc403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# column order in CSV file\n",
        "column_names = ['sepal_length','sepal_width', 'petal_length','petal_width' ,'species']\n",
        "\n",
        "feature_names=column_names[:-1]\n",
        "label_name = column_names[-1]\n",
        "\n",
        "print(\"Features: {}\".format(feature_names))\n",
        "print(\"Label:{}\".format(label_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
            "Label:species\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vasRufkskWGo",
        "colab_type": "text"
      },
      "source": [
        "Each label is associated with string name (for example, \"setosa\"), but machine learning typically relies on numeric values. The label numbers are mapped to a named representation, such as:\n",
        "\n",
        "* 0: Iris setosa\n",
        "* 1: Iris versicolor\n",
        "* 2: Iris virginica\n",
        "\n",
        "For more information about features and labels, see the ML Terminology section of the Machine Learning Crash Course."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvKybIfFmOsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names= ['Iris setosa美', 'Iris versiocolor雜色', 'Iris Virginica']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYqOrZ1rm_I1",
        "colab_type": "text"
      },
      "source": [
        "##創建一個 tf.data.Dataset ：\n",
        "\n",
        "* 由於數據集是CSV格式的文本文件，因此請使用make_csv_dataset函數將數據解析為合適的格式。\n",
        "* 由於此函數為訓練模型生成數據，因此默認行為是對數據（`shuffle=True, shuffle_buffer_size=10000`）進行混洗，並永遠重複數據集（`num_epochs=None`）。我們還設置了`batch_size`參數。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiac_gJuniY6",
        "colab_type": "code",
        "outputId": "800740fe-c5b0-4568-8687-8da2a12c200e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_dataset = tf.contrib.data.make_csv_dataset(\n",
        "    train_dataset_fp,\n",
        "    batch_size,\n",
        "    column_names=column_names,\n",
        "    label_name=label_name,\n",
        "    num_epochs=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0813 15:21:59.376907 139797118093184 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0813 15:21:59.378755 139797118093184 deprecation.py:323] From <ipython-input-7-b38e4b2864a1>:8: make_csv_dataset (from tensorflow.contrib.data.python.ops.readers) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.make_csv_dataset(...)`.\n",
            "W0813 15:21:59.502829 139797118093184 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/experimental/ops/readers.py:499: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVpcckeeqL1I",
        "colab_type": "code",
        "outputId": "2a24b758-9abd-4eb4-ee8b-9f596ddec06f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "features, labels = next(iter(train_dataset))\n",
        "\n",
        "features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('sepal_length',\n",
              "              <tf.Tensor: id=65, shape=(32,), dtype=float32, numpy=\n",
              "              array([6.9, 5. , 6.4, 5.1, 6. , 4.9, 6. , 6.8, 6.9, 7.4, 5.1, 4.9, 6.1,\n",
              "                     4.6, 6.2, 5.7, 6.5, 5.5, 6.4, 5. , 4.9, 5. , 7.9, 6.2, 5.7, 6. ,\n",
              "                     6.5, 6.7, 6.7, 6.3, 5.5, 5. ], dtype=float32)>),\n",
              "             ('sepal_width',\n",
              "              <tf.Tensor: id=66, shape=(32,), dtype=float32, numpy=\n",
              "              array([3.2, 3. , 3.2, 3.8, 2.2, 2.4, 2.9, 3.2, 3.1, 2.8, 3.8, 2.5, 2.8,\n",
              "                     3.2, 2.2, 2.8, 3. , 3.5, 3.1, 3.6, 3. , 3.5, 3.8, 3.4, 3.8, 2.7,\n",
              "                     3.2, 3.1, 3. , 3.3, 2.4, 2. ], dtype=float32)>),\n",
              "             ('petal_length',\n",
              "              <tf.Tensor: id=63, shape=(32,), dtype=float32, numpy=\n",
              "              array([5.7, 1.6, 4.5, 1.6, 5. , 3.3, 4.5, 5.9, 5.1, 6.1, 1.9, 4.5, 4. ,\n",
              "                     1.4, 4.5, 4.5, 5.2, 1.3, 5.5, 1.4, 1.4, 1.6, 6.4, 5.4, 1.7, 5.1,\n",
              "                     5.1, 5.6, 5.2, 4.7, 3.8, 3.5], dtype=float32)>),\n",
              "             ('petal_width',\n",
              "              <tf.Tensor: id=64, shape=(32,), dtype=float32, numpy=\n",
              "              array([2.3, 0.2, 1.5, 0.2, 1.5, 1. , 1.5, 2.3, 2.3, 1.9, 0.4, 1.7, 1.3,\n",
              "                     0.2, 1.5, 1.3, 2. , 0.2, 1.8, 0.2, 0.2, 0.6, 2. , 2.3, 0.3, 1.6,\n",
              "                     2. , 2.4, 2.3, 1.6, 1.1, 1. ], dtype=float32)>)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0Q7Gj4dqm0d",
        "colab_type": "text"
      },
      "source": [
        "Notice  that like-features are grouped together, or batched. Each example row's fields are appended to the corresponding feature array. \n",
        "Change the batch_size to set the number of examples stored in these feature arrays.\n",
        "\n",
        "You can start to see some clusters by plotting a few features from the batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXLCMirIq8Dc",
        "colab_type": "code",
        "outputId": "e2c6995f-736d-4bc5-ee50-5fb7cfd8ead6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.scatter(features['petal_length'].numpy(),\n",
        "            features['sepal_length'].numpy(),\n",
        "            c=labels.numpy(),\n",
        "            cmap='viridis')\n",
        "\n",
        "plt.xlabel(\"petal length\")\n",
        "plt.ylabel(\"Sepal length\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xhm7eb1L2RCm",
        "colab_type": "text"
      },
      "source": [
        "To simplify the model building step, create a function to repackage the features dictionary into a single array with shape:`` (batch_size, num_features)``.\n",
        "\n",
        "\n",
        "This function uses the `tf.stack `method which takes values from a list of tensors and creates a combined tensor at the specified dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHabTbu-2lI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pack_features_vector(features, labels):\n",
        "  \"\"\"Pack the features into a single array.\"\"\"\n",
        "  features = tf.stack(list(features.values()), axis=1)\n",
        "  return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIeB0ofs3j8p",
        "colab_type": "text"
      },
      "source": [
        "Then use the ` tf.data.Dataset.map `method to pack the  `features `of each  ``(features,label)`` pair into the training dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnxjcHiQ4AnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = train_dataset.map(pack_features_vector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO0pHjvN4X-i",
        "colab_type": "text"
      },
      "source": [
        "The features element of the` Dataset` are now arrays with shape``(batch_size, num_features)``. Let's look at the first few examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBJyZFCh4qFE",
        "colab_type": "code",
        "outputId": "64cf7d66-57fc-4800-a0a6-5804ed88c989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "features, labels =next(iter(train_dataset))\n",
        "\n",
        "print(features[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[6.9 3.2 5.7 2.3]\n",
            " [5.  3.  1.6 0.2]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [6.  2.2 5.  1.5]], shape=(5, 4), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnJzUOrZ5Akk",
        "colab_type": "text"
      },
      "source": [
        "##Select the type of model\n",
        "Why model?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LsaVrtNM3Tx5"
      },
      "source": [
        "## Select the type of model\n",
        "\n",
        "### Why model?\n",
        "\n",
        "1. A *[model](https://developers.google.com/machine-learning/crash-course/glossary#model)* is a relationship between `features` and `the label`.  \n",
        "\n",
        "* For the Iris classification problem, the model defines the relationship between` the sepal and petal` measurements and `the predicted Iris species`. \n",
        "\n",
        "* Some simple models can be described with a few` lines of algebra`, but` complex machine learning models` have a large number of parameters that are difficult to summarize.\n",
        "\n",
        "2. Could you determine the relationship between the four features and the Iris species *without* using machine learning?  \n",
        "* That is, could you use traditional programming techniques (for example, a lot of conditional statements) to create a model?  Perhaps—if you analyzed the dataset long enough to determine the relationships between` petal and sepal` measurements to a particular species. And this becomes difficult—maybe impossible—on more complicated datasets.\n",
        "* A good machine learning approach *determines the model for you*. If you feed enough representative examples into the right machine learning model type, the program will figure out the relationships for you.\n",
        "\n",
        "### Select the model\n",
        "\n",
        "1. We need to select the kind of model to train. There are many types of models and picking a good one takes experience. \n",
        "* This tutorial uses a neural network to solve the Iris classification problem. *[Neural networks](https://developers.google.com/machine-learning/glossary/#neural_network)* can find complex relationships between features and the label. \n",
        "* It is a highly-structured graph, organized into one or more *[hidden layers](https://developers.google.com/machine-learning/glossary/#hidden_layer)*. \n",
        "* Each hidden layer consists of one or more *[neurons](https://developers.google.com/machine-learning/glossary/#neuron)*. \n",
        "* There are several categories of neural networks and this program uses a` dense`, or *[fully-connected neural network](https://developers.google.com/machine-learning/glossary/#fully_connected_layer)*: \n",
        "* the neurons in one layer receive input connections from *every* neuron in the previous layer.\n",
        "For example, Figure 2 illustrates a dense neural network consisting of an` input layer`, two `hidden layers`, and an `output layer`:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://www.tensorflow.org/images/custom_estimators/full_network.png\"\n",
        "         alt=\"A diagram of the network architecture: Inputs, 2 hidden layers, and outputs\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figure 2.</b> A neural network with features, hidden layers, and predictions.<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "When the model from Figure 2 is trained and fed an unlabeled example, it yields three predictions: the likelihood that this flower is the given Iris species. This prediction is called *[inference](https://developers.google.com/machine-learning/crash-course/glossary#inference)*. For this example, the sum of the output predictions is 1.0. In Figure 2, this prediction breaks down as: `0.02` for *Iris setosa*, `0.95` for *Iris versicolor*, and `0.03` for *Iris virginica*. This means that the model predicts—with 95% probability—that an unlabeled example flower is an *Iris versicolor*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPvzuXrJ8_SL",
        "colab_type": "text"
      },
      "source": [
        "##Create a model using Keras ：\n",
        "* The TensorFlow` tf.keras` API is the preferred way to create models and layers. \n",
        "This makes it easy to build models and experiment while Keras handles the complexity of connecting everything together.\n",
        "\n",
        "* The` tf.keras.Sequential model` is a linear stack of layers. \n",
        "Its constructor takes a list of layer instances, in this case,`two Dense layers` with 10 nodes each, and `an output layer` with 3 nodes representing our label predictions.\n",
        "* The first layer's input_shape parameter corresponds to the number of features from the dataset, and is required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YNFVkZk852o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " model = tf.keras.Sequential([\n",
        "     tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),  # input shape required\n",
        "     tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
        "     tf.keras.layers.Dense(3)\n",
        " ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4bl3E19_p4C",
        "colab_type": "text"
      },
      "source": [
        "The *activation function* determines the output shape of each node in the layer. \n",
        "* These non-linearities are important—without them the model would be equivalent to a single layer. \n",
        "* There are many available activations, but ReLU is common for hidden layers.\n",
        "\n",
        "The ideal number of hidden layers and neurons depends on the problem and the dataset.\n",
        "* Like many aspects of machine learning, picking the best shape of the neural network requires a mixture of knowledge and experimentation.\n",
        "* As a rule of thumb, increasing the number of hidden layers and neurons typically creates a more powerful model, which requires more data to train effectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sviK4031AYL8",
        "colab_type": "text"
      },
      "source": [
        "##Using the model：\n",
        "Let's have a quick look at what this model does to a batch of features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQmNegd9ATBu",
        "colab_type": "code",
        "outputId": "823bb915-aa9b-4784-ca7a-6440fc2676e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "predictions = model(features)\n",
        "predictions[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=206, shape=(5, 3), dtype=float32, numpy=\n",
              "array([[-0.5115956 , -0.08028889, -0.57693887],\n",
              "       [-0.0559656 ,  0.1066469 , -0.1421272 ],\n",
              "       [-0.34076563, -0.03238136, -0.41694808],\n",
              "       [-0.18408546,  0.0205173 , -0.24399105],\n",
              "       [-0.21489766,  0.01228814, -0.3135725 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po_4SkO9A2a1",
        "colab_type": "text"
      },
      "source": [
        "Here, each example returns a [logit](https://developers.google.com/machine-learning/crash-course/glossary#logits) for each class.\n",
        "\n",
        "To convert these logits to` a probability `for each class, use the [softmax](https://developers.google.com/machine-learning/crash-course/glossary#softmax) function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsTCPItABCLz",
        "colab_type": "code",
        "outputId": "e8a3e4c0-150c-445a-f165-36b6454505bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "tf.nn.softmax(predictions[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=212, shape=(5, 3), dtype=float32, numpy=\n",
              "array([[0.2876859 , 0.4428256 , 0.26948857],\n",
              "       [0.3232034 , 0.3802749 , 0.29652166],\n",
              "       [0.30414817, 0.41401377, 0.28183803],\n",
              "       [0.3155678 , 0.38721353, 0.29721862],\n",
              "       [0.31634554, 0.3970336 , 0.28662086]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2oKKwR4B9mT",
        "colab_type": "text"
      },
      "source": [
        "Taking the` tf.argmax` across classes gives us the predicted class index. But, the model hasn't been trained yet, so these aren't good predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfI-2ChlCy5A",
        "colab_type": "code",
        "outputId": "4aebf6b1-11e6-4b00-ecd0-90cf203e54d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(\"Predictions:{}\".format(tf.argmax(predictions, axis=1)))\n",
        "print (\"    Labels:{}\".format(labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions:[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "    Labels:[2 0 1 0 2 1 1 2 2 2 0 2 1 0 1 1 2 0 2 0 0 0 2 2 0 1 2 2 2 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJc1DX2mDo03",
        "colab_type": "text"
      },
      "source": [
        "##訓練模型 ：\n",
        "\n",
        "* 當模型逐漸優化或模型學習數據集時，訓練是機器學習的階段。目標是充分了解訓練數據集的結構，以便對看不見的數據進行預測。\n",
        "* 如果您對訓練數據集了解得太多，那麼預測僅適用於它已經看到的數據，並且不會被推廣。這個問題被稱為`過度擬合` - 就像記憶答案而不是理解如何解決問題。\n",
        "\n",
        "* Iris分類問題是`監督機器學習`*[supervised machine learning](https://developers.google.com/machine-learning/glossary/#supervised_machine_learning)*:的一個例子：模型是從包含標籤的示例中訓練出來的。\n",
        "* 在`無監督的機器`學習 *[unsupervised machine learning](https://developers.google.com/machine-learning/glossary/#unsupervised_machine_learning)*中，示例不包含標籤。相反，模型通常在特徵中找到模式。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8l_GEHCEvxF",
        "colab_type": "text"
      },
      "source": [
        "##定義損失和梯度函數 ：\n",
        "培訓和評估階段都需要計算模型的損失。這可以衡量模型預測與所需標籤的關係，換句話說，模型的執行情況有多糟糕。我們希望最小化或優化此值。\n",
        "\n",
        "我們的模型將使用*[tf.keras.losses.categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/losses/sparse_softmax_cross_entropy) *函數計算其損失，該函數獲取模型的類概率預測和所需標籤，並返回示例中的平均損失。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vy11XPAFK7D",
        "colab_type": "code",
        "outputId": "df272714-e2c0-4ba7-ba33-a7422a11a2a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "def loss(model, x, y):\n",
        "  y_ =model(x)\n",
        "  return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n",
        "\n",
        "l = loss(model, features, labels)\n",
        "print(\"Loss test: {}\".format(l))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss test: 1.1355464458465576\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlfnvHqxHT_V",
        "colab_type": "text"
      },
      "source": [
        "Use the  [tf.GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape)context to calculate the *[gradients](https://developers.google.com/machine-learning/crash-course/glossary#gradient)* used to optimize our model. For more examples of this, see the  [eager execution guide](https://www.tensorflow.org/guide/eager). execution guide."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSssGRiwHZlw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def grad(model, inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    losses_value = loss(model, inputs, targets)\n",
        "  return losses_value, tape.gradient(losses_value, model.trainable_variables)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UAqTLs6In_6",
        "colab_type": "text"
      },
      "source": [
        "## Create an optimizer\n",
        "\n",
        "An *[optimizer](https://developers.google.com/machine-learning/crash-course/glossary#optimizer)* applies the computed gradients to the model's variables to minimize the `loss` function. \n",
        "\n",
        "* You can think of the loss function as a curved surface (see Figure 3) and we want to find its lowest point by walking around. \n",
        "* The gradients point in the direction of steepest ascent—so we'll travel the opposite way and move down the hill. By iteratively calculating the loss and gradient for each batch, we'll adjust the model during training. \n",
        "* Gradually, the model will find the best combination of weights and bias to minimize loss. And the lower the loss, the better the model's predictions.\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://cs231n.github.io/assets/nn3/opt1.gif\" width=\"70%\"\n",
        "         alt=\"Optimization algorithms visualized over time in 3D space.\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figure 3.</b> Optimization algorithms visualized over time in 3D space.<br/>(Source: <a href=\"http://cs231n.github.io/neural-networks-3/\">Stanford class CS231n</a>, MIT License, Image credit: <a href=\"https://twitter.com/alecrad\">Alec Radford</a>)\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "TensorFlow has many [optimization algorithms](https://www.tensorflow.org/api_guides/python/train) available for training. This model uses the [tf.train.GradientDescentOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer) that implements the *[stochastic gradient descent](https://developers.google.com/machine-learning/crash-course/glossary#gradient_descent)* (SGD) algorithm. The `learning_rate` sets the step size to take for each iteration down the hill. This is a *hyperparameter* that you'll commonly adjust to achieve better results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdTP93IVJlyE",
        "colab_type": "text"
      },
      "source": [
        "###Let's setup the optimizer and the global_step counter:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYEhfqXeJpaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "global_step = tf.Variable(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbfTFdhpKbTf",
        "colab_type": "text"
      },
      "source": [
        "###We'll use this to calculate a single optimization step:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ1EdTXGKku0",
        "colab_type": "code",
        "outputId": "ab27e483-14a0-42b1-f567-6920957f2d07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "losses_value, grads = grad(model, features, labels)\n",
        "\n",
        "print(\"Step: {}, Initial Loss: {}\".format(global_step.numpy(),\n",
        "                                          losses_value.numpy()))\n",
        "\n",
        "optimizer.apply_gradients(zip(grads, model.trainable_variables), global_step)\n",
        "\n",
        "print(\"Step: {},         Loss: {}\".format(global_step.numpy(),\n",
        "                                          loss(model, features, labels).numpy()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step: 0, Initial Loss: 1.1355464458465576\n",
            "Step: 1,         Loss: 1.133716106414795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_ytNHLcMEq8",
        "colab_type": "text"
      },
      "source": [
        "##訓練循環( Training loop) ：\n",
        "\n",
        "With all the pieces in place, the model is ready for training! A training loop feeds the dataset examples into the model to help it make better predictions. The following code block sets up these training steps:\n",
        "\n",
        "1. Iterate each *epoch*. An epoch is one pass through the dataset.\n",
        "2. Within an epoch, iterate over each example in the training `Dataset` grabbing its *features* (`x`) and *label* (`y`).\n",
        "3. Using the example's features, make a prediction and compare it with the label. Measure the inaccuracy of the prediction and use that to calculate the model's loss and gradients.\n",
        "4. Use an `optimizer` to update the model's variables.\n",
        "5. Keep track of some stats for visualization.\n",
        "6. Repeat for each epoch.\n",
        "\n",
        "The `num_epochs` variable is the number of times to loop over the dataset collection. Counter-intuitively, training a model longer does not guarantee a better model. `num_epochs` is a *[hyperparameter](https://developers.google.com/machine-learning/glossary/#hyperparameter)* that you can tune. Choosing the right number usually requires both experience and experimentation."
      ]
    }
  ]
}